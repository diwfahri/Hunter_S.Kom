{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Object</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b'@BukaBantuan tolong cepat bantu proses order...</td>\n",
       "      <td>Bukalapak</td>\n",
       "      <td>Negatif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b'@BukaBantuan Kalau bisa sih barang nya di ja...</td>\n",
       "      <td>Bukalapak</td>\n",
       "      <td>Negatif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>b'@BukaBantuan Terima kasih, kak. Kendala suda...</td>\n",
       "      <td>Bukalapak</td>\n",
       "      <td>Positif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>b'@Ndons_Back: Min @bukalapak @BukaBantuan pej...</td>\n",
       "      <td>Bukalapak</td>\n",
       "      <td>Negatif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>b'@BukaBantuan Belum ada masuk kak email nya'</td>\n",
       "      <td>Bukalapak</td>\n",
       "      <td>Negatif</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Tweet     Object Sentiment\n",
       "0  b'@BukaBantuan tolong cepat bantu proses order...  Bukalapak   Negatif\n",
       "1  b'@BukaBantuan Kalau bisa sih barang nya di ja...  Bukalapak   Negatif\n",
       "2  b'@BukaBantuan Terima kasih, kak. Kendala suda...  Bukalapak   Positif\n",
       "3  b'@Ndons_Back: Min @bukalapak @BukaBantuan pej...  Bukalapak   Negatif\n",
       "4      b'@BukaBantuan Belum ada masuk kak email nya'  Bukalapak   Negatif"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#Import dataset\n",
    "data=pd.read_excel(\"Dataset_Marketplace.xlsx\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleansing Result : \n",
      "\n",
      "0    tolong cepat bantu proses orderan diteruskan k...\n",
      "1    Kalau bisa sih barang nya di jadiin aja jangan...\n",
      "2    Terima kasih kak Kendala sudah terselesaikan s...\n",
      "3    Back Min pejualan film porno banyak di tempat ...\n",
      "4                        Belum ada masuk kak email nya\n",
      "Name: Tweet, dtype: object\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Cleansing\n",
    "import string \n",
    "import re #regex library\n",
    "\n",
    "def remove_tweet_special(text):\n",
    "    # remove tab, new line, ans back slice\n",
    "    text = text.replace('\\\\t',\" \").replace('\\\\n',\" \").replace('\\\\u',\" \").\n",
    "        replace('\\\\',\"\")\n",
    "    # remove non ASCII (emoticon, chinese word, .etc)\n",
    "    text = text.encode('ascii', 'replace').decode('ascii')\n",
    "    # remove mention, link, hashtag\n",
    "    text = ' '.join(re.sub(\"([@#x][A-Za-z0-9]+)|(\\w+:\\/\\/\\S+)\",\" \", text).\n",
    "        split())\n",
    "    # remove b',RT, and &amp\n",
    "    text = text.replace(\"b'\",\"\").replace('amp',\"\").replace('RT',\"\")\n",
    "    # remove incomplete URL\n",
    "    return text.replace(\"http://\", \" \").replace(\"https://\", \" \")\n",
    "                \n",
    "data['Tweet'] = data['Tweet'].apply(remove_tweet_special)\n",
    "\n",
    "#remove number\n",
    "def remove_number(text):\n",
    "    return  re.sub(r\"\\d+\", \"\", text)\n",
    "\n",
    "data['Tweet'] = data['Tweet'].apply(remove_number)\n",
    "\n",
    "#remove punctuation\n",
    "def remove_punctuation(text):\n",
    "    return text.translate(str.maketrans(\"\",\"\",string.punctuation))\n",
    "\n",
    "data['Tweet'] = data['Tweet'].apply(remove_punctuation)\n",
    "\n",
    "#remove whitespace leading & trailing\n",
    "def remove_whitespace_LT(text):\n",
    "    return text.strip()\n",
    "\n",
    "data['Tweet'] = data['Tweet'].apply(remove_whitespace_LT)\n",
    "\n",
    "#remove multiple whitespace into single whitespace\n",
    "def remove_whitespace_multiple(text):\n",
    "    return re.sub('\\s+',' ',text)\n",
    "\n",
    "data['Tweet'] = data['Tweet'].apply(remove_whitespace_multiple)\n",
    "\n",
    "# remove single char\n",
    "def remove_singl_char(text):\n",
    "    return re.sub(r\"\\b[a-zA-Z]\\b\", \"\", text)\n",
    "\n",
    "data['Tweet'] = data['Tweet'].apply(remove_singl_char)\n",
    "\n",
    "#view\n",
    "data['tweet_cleansing'] = data['Tweet'].apply(remove_singl_char)\n",
    "\n",
    "print('Cleansing Result : \\n') \n",
    "print(data['Tweet'].head())\n",
    "print('\\n\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Case Folding Result : \n",
      "\n",
      "0    tolong cepat bantu proses orderan diteruskan k...\n",
      "1    kalau bisa sih barang nya di jadiin aja jangan...\n",
      "2    terima kasih kak kendala sudah terselesaikan s...\n",
      "3    back min pejualan film porno banyak di tempat ...\n",
      "4                        belum ada masuk kak email nya\n",
      "Name: tweet_casefolding, dtype: object\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ------ Case Folding --------\n",
    "# gunakan fungsi Series.str.lower() pada Pandas\n",
    "data['tweet_casefolding'] = data['tweet_cleansing'].str.lower()\n",
    "\n",
    "\n",
    "print('Case Folding Result : \\n')\n",
    "print(data['tweet_casefolding'].head())\n",
    "print('\\n\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     tolong cepat bantu proses orderan diteruskan k...\n",
       "1     kalau bisa sih barang nya di jadiin aja jangan...\n",
       "2     terima kasih kak kendala sudah terselesaikan s...\n",
       "3     back min pejualan film porno banyak di tempat ...\n",
       "4                        belum ada masuk kak email nya \n",
       "                            ...                        \n",
       "75                     iya dong min biar bisa on terus \n",
       "76                 makasih min sukses selalu bukalapak \n",
       "77                                   ini knp gkbisa ya \n",
       "78    halooo barang sudah dipick up driver tapi enta...\n",
       "79    karena sepertinya mulai ketahuan saya arahkan ...\n",
       "Name: tweet_convertnegation, Length: 80, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def convert_negation(text):\n",
    "    text=''.join(i+' ' if i != 'gak' else i for i in text.split())\n",
    "    text=''.join(i+' ' if i != 'ga' else i for i in text.split())\n",
    "    text=''.join(i+' ' if i != 'ngga' else i for i in text.split())\n",
    "    text=''.join(i+' ' if i != 'gk' else i for i in text.split())\n",
    "    text=''.join(i+' ' if i != 'nggak' else i for i in text.split())\n",
    "    text=''.join(i+' ' if i != 'enggak' else i for i in text.split())\n",
    "    text=''.join(i+' ' if i != 'tidak' else i for i in text.split())\n",
    "    text=''.join(i+' ' if i != 'tdk' else i for i in text.split())\n",
    "    text=''.join(i+' ' if i != 'tida' else i for i in text.split())\n",
    "    text=''.join(i+' ' if i != 'tak' else i for i in text.split())\n",
    "    text=''.join(i+' ' if i != 'bukan' else i for i in text.split())\n",
    "    text=''.join(i+' ' if i != 'bkan' else i for i in text.split())\n",
    "    text=''.join(i+' ' if i != 'bkn' else i for i in text.split())\n",
    "    text=''.join(i+' ' if i != 'jangan' else i for i in text.split())\n",
    "    text=''.join(i+' ' if i != 'jgn' else i for i in text.split())\n",
    "    return ''.join(i+' ' if i != 'kurang' else i for i in text.split())\n",
    "              \n",
    "data['tweet_convertnegation'] = data['tweet_casefolding'].apply(convert_negation)\n",
    "data['tweet_convertnegation'].head(80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     [tolong, cepat, bantu, proses, orderan, diteru...\n",
      "1     [kalau, bisa, sih, barang, nya, di, jadiin, aj...\n",
      "2     [terima, kasih, kak, kendala, sudah, terselesa...\n",
      "3     [back, min, pejualan, film, porno, banyak, di,...\n",
      "4                  [belum, ada, masuk, kak, email, nya]\n",
      "                            ...                        \n",
      "75              [iya, dong, min, biar, bisa, on, terus]\n",
      "76            [makasih, min, sukses, selalu, bukalapak]\n",
      "77                               [ini, knp, gkbisa, ya]\n",
      "78    [halooo, barang, sudah, dipick, up, driver, ta...\n",
      "79    [karena, sepertinya, mulai, ketahuan, saya, ar...\n",
      "Name: tweet_tokens, Length: 80, dtype: object\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ------ Tokenizing ---------\n",
    "# import word_tokenize from NLTK\n",
    "from nltk.tokenize import word_tokenize \n",
    "\n",
    "def tokenizing(text):\n",
    "    return word_tokenize(text)\n",
    "\n",
    "data['tweet_tokens'] = data['tweet_convertnegation'].apply(tokenizing)\n",
    "\n",
    "print(data['tweet_tokens'].head(80))\n",
    "print('\\n\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     [tolong, cepat, bantu, proses, orderan, diteru...\n",
       "1     [kalau, bisa, sih, barang, nya, di, jadikan, s...\n",
       "2     [terima, kasih, kakak, kendala, sudah, tersele...\n",
       "3     [kembali, admin, pejualan, film, pornografi, b...\n",
       "4                [belum, ada, masuk, kakak, email, nya]\n",
       "                            ...                        \n",
       "75            [iya, dong, admin, biar, bisa, on, terus]\n",
       "76      [terimakasih, admin, sukses, selalu, bukalapak]\n",
       "77                        [ini, kenapa, tidakbisa, iya]\n",
       "78    [halo, barang, sudah, dijemput, up, sopir, tap...\n",
       "79    [karena, sepertinya, mulai, ketahuan, saya, ar...\n",
       "Name: tweet_normalization, Length: 80, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalization_word = pd.read_excel(\"normalization.xlsx\")\n",
    "\n",
    "normalization_word_dict = {}\n",
    "\n",
    "for index, row in normalization_word.iterrows():\n",
    "    if row[0] not in normalization_word_dict:\n",
    "        normalization_word_dict[row[0]] = row[1] \n",
    "\n",
    "def normalization_term(document):\n",
    "    return [normalization_word_dict[term] if term in normalization_word_dict else term for term in document]\n",
    "\n",
    "data['tweet_normalization'] = data['tweet_tokens'].apply(normalization_term)\n",
    "\n",
    "data['tweet_normalization'].head(80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     [cepat, bantu, proses, orderan, diteruskan, bu...\n",
       "1                         [barang, kembalikan, dananya]\n",
       "2               [terima, kasih, kendala, terselesaikan]\n",
       "3     [admin, pejualan, film, pornografi, janganrusa...\n",
       "4                                        [masuk, email]\n",
       "                            ...                        \n",
       "75                                          [admin, on]\n",
       "76              [terimakasih, admin, sukses, bukalapak]\n",
       "77                                          [tidakbisa]\n",
       "78    [barang, dijemput, sopir, barangnya, status, p...\n",
       "79                       [arahkan, transfer, dana, sms]\n",
       "Name: tweet_stopwordremoval, Length: 80, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from Sastrawi.StopWordRemover.StopWordRemoverFactory import StopWordRemoverFactory\n",
    "\n",
    "stopword_factory = StopWordRemoverFactory()\n",
    "stopwords_txt = open(\"stopword.txt\", \"r\")\n",
    "\n",
    "\n",
    "stopword_dict = []\n",
    "for word in stopwords_txt:\n",
    "    stopword_dict.append(word.rstrip())\n",
    "list_stopword=stopword_factory.get_stop_words()+stopword_dict\n",
    "\n",
    "def remove_stopword(words):\n",
    "    return [word for word in words if word not in list_stopword]\n",
    "\n",
    "data['tweet_stopwordremoval']= data['tweet_normalization'].apply(remove_stopword)\n",
    "data['tweet_stopwordremoval'].head(80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     [cepat, bantu, proses, order, terus, bukadompe...\n",
       "1                               [barang, kembali, dana]\n",
       "2                     [terima, kasih, kendala, selesai]\n",
       "3     [admin, jual, film, pornografi, janganrusak, p...\n",
       "4                                        [masuk, email]\n",
       "                            ...                        \n",
       "75                                          [admin, on]\n",
       "76              [terimakasih, admin, sukses, bukalapak]\n",
       "77                                          [tidakbisa]\n",
       "78    [barang, jemput, sopir, barang, status, jual, ...\n",
       "79                          [arah, transfer, dana, sms]\n",
       "Name: tweet_stemming, Length: 80, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
    "factory = StemmerFactory()\n",
    "stemmer = factory.create_stemmer()\n",
    "\n",
    "def Stem(remove_stopword): \n",
    "    return [stemmer.stem(word) for word in remove_stopword]\n",
    "\n",
    "data['tweet_stemming']= data['tweet_stopwordremoval'].apply(Stem)\n",
    "data['tweet_stemming'].head(80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_excel(\"Preprocessing.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
